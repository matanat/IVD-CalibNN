{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ae6ad1e0d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "from regression_net import RegressionNet\n",
    "from data import normalize_columns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse input and create dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaterialConfigurations --> generated samples of parameter-configurations; \n",
    "First line = name of each parameter\n",
    "ParameterBouunds --> ranges used for the different parameters during sampling;\n",
    "First line = name of each parameter\n",
    "IDP_Results and ROM_ Results --> files with the output generated by model simulations; \n",
    "First line = applied moment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_id</th>\n",
       "      <th>LoadCase</th>\n",
       "      <th>Moment</th>\n",
       "      <th>C10Nucleus</th>\n",
       "      <th>C01Nucleus</th>\n",
       "      <th>C10Annulus</th>\n",
       "      <th>K1Annulus</th>\n",
       "      <th>K2Annulus</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>K1Circ</th>\n",
       "      <th>K2Circ</th>\n",
       "      <th>K1Rad</th>\n",
       "      <th>K2Rad</th>\n",
       "      <th>FiberAngle</th>\n",
       "      <th>FiberAngleCirc</th>\n",
       "      <th>FiberAngleRad</th>\n",
       "      <th>y_ROM</th>\n",
       "      <th>y_IDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803711</td>\n",
       "      <td>0.372070</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.454102</td>\n",
       "      <td>0.940430</td>\n",
       "      <td>0.883789</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.420898</td>\n",
       "      <td>0.493164</td>\n",
       "      <td>0.526367</td>\n",
       "      <td>0.653320</td>\n",
       "      <td>0.317383</td>\n",
       "      <td>0.126046</td>\n",
       "      <td>0.530391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385742</td>\n",
       "      <td>0.579102</td>\n",
       "      <td>0.416992</td>\n",
       "      <td>0.981445</td>\n",
       "      <td>0.227539</td>\n",
       "      <td>0.487305</td>\n",
       "      <td>0.602539</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.307617</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.215820</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.522663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>0.788086</td>\n",
       "      <td>0.172852</td>\n",
       "      <td>0.954102</td>\n",
       "      <td>0.172852</td>\n",
       "      <td>0.858398</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.600586</td>\n",
       "      <td>0.395508</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>0.860352</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190430</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>0.827148</td>\n",
       "      <td>0.661133</td>\n",
       "      <td>0.961914</td>\n",
       "      <td>0.901367</td>\n",
       "      <td>0.641602</td>\n",
       "      <td>0.733398</td>\n",
       "      <td>0.237305</td>\n",
       "      <td>0.750977</td>\n",
       "      <td>0.319336</td>\n",
       "      <td>0.186156</td>\n",
       "      <td>0.526288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741211</td>\n",
       "      <td>0.545898</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.670898</td>\n",
       "      <td>0.233398</td>\n",
       "      <td>0.625977</td>\n",
       "      <td>0.411133</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.645508</td>\n",
       "      <td>0.725586</td>\n",
       "      <td>0.334961</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>0.527357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>1019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.900391</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.120541</td>\n",
       "      <td>0.632732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>1020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>0.228516</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.634766</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.586695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>1021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.939453</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.347656</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.144379</td>\n",
       "      <td>0.467184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>1022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.335937</td>\n",
       "      <td>0.059934</td>\n",
       "      <td>0.653710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>1023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.667969</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.135796</td>\n",
       "      <td>0.572153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       config_id  LoadCase  Moment  C10Nucleus  C01Nucleus  C10Annulus  \\\n",
       "0              0       0.0     0.0    0.803711    0.372070    0.012695   \n",
       "1              1       0.0     0.0    0.385742    0.579102    0.416992   \n",
       "2              2       0.0     0.0    0.088867    0.211914    0.788086   \n",
       "3              3       0.0     0.0    0.190430    0.098633    0.016602   \n",
       "4              4       0.0     0.0    0.741211    0.545898    0.682617   \n",
       "...          ...       ...     ...         ...         ...         ...   \n",
       "20475       1019       1.0     1.0    0.166016    0.900391    0.257812   \n",
       "20476       1020       1.0     1.0    0.037109    0.291016    0.820312   \n",
       "20477       1021       1.0     1.0    0.716797    0.064453    0.230469   \n",
       "20478       1022       1.0     1.0    0.765625    0.220703    0.050781   \n",
       "20479       1023       1.0     1.0    0.822266    0.691406    0.275391   \n",
       "\n",
       "       K1Annulus  K2Annulus     Kappa    K1Circ    K2Circ     K1Rad     K2Rad  \\\n",
       "0       0.454102   0.940430  0.883789  0.448242  0.026367  0.420898  0.493164   \n",
       "1       0.981445   0.227539  0.487305  0.602539  0.022461  0.307617  0.088867   \n",
       "2       0.172852   0.954102  0.172852  0.858398  0.348633  0.016602  0.600586   \n",
       "3       0.065430   0.827148  0.661133  0.961914  0.901367  0.641602  0.733398   \n",
       "4       0.670898   0.233398  0.625977  0.411133  0.469727  0.825195  0.588867   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "20475   0.212891   0.921875  0.050781  0.902344  0.275391  0.746094  0.535156   \n",
       "20476   0.220703   0.228516  0.140625  0.726562  0.410156  0.634766  0.816406   \n",
       "20477   0.828125   0.949219  0.939453  0.890625  0.347656  0.410156  0.972656   \n",
       "20478   0.945312   0.212891  0.107422  0.929688  0.552734  0.400391  0.230469   \n",
       "20479   0.291016   0.007812  0.667969  0.843750  0.162109  0.392578  0.322266   \n",
       "\n",
       "       FiberAngle  FiberAngleCirc  FiberAngleRad     y_ROM     y_IDP  \n",
       "0        0.526367        0.653320       0.317383  0.126046  0.530391  \n",
       "1        0.215820        0.506836       0.532227  0.068406  0.522663  \n",
       "2        0.395508        0.745117       0.860352  0.041758  0.524259  \n",
       "3        0.237305        0.750977       0.319336  0.186156  0.526288  \n",
       "4        0.645508        0.725586       0.334961  0.037950  0.527357  \n",
       "...           ...             ...            ...       ...       ...  \n",
       "20475    0.431641        0.216797       0.921875  0.120541  0.632732  \n",
       "20476    0.480469        0.199219       0.822266  0.102200  0.586695  \n",
       "20477    0.357422        0.187500       0.193359  0.144379  0.467184  \n",
       "20478    0.890625        0.984375       0.335937  0.059934  0.653710  \n",
       "20479    0.873047        0.203125       0.064453  0.135796  0.572153  \n",
       "\n",
       "[20480 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = \"datasets/Large/\"\n",
    "placeholder = \"\"\n",
    "\n",
    "LoadCases = ['Flexion', 'AxialRotation', 'Extension', 'LateralBending']\n",
    "\n",
    "output_files = [\n",
    "    {'Name': 'Flexion', 'ROM': f\"{ds_path}ROM_Results_Flexion_{placeholder}wMoment.csv\", 'IDP': f\"{ds_path}IDP_Results_Flexion_{placeholder}wMoment.csv\"},\n",
    "    {'Name': 'AxialRotation', 'ROM': f\"{ds_path}ROM_Results_AxialRotation_{placeholder}wMoment.csv\", 'IDP': f\"{ds_path}IDP_Results_AxialRotation_{placeholder}wMoment.csv\"},\n",
    "    {'Name': 'Extension', 'ROM': f\"{ds_path}ROM_Results_Extension_{placeholder}wMoment.csv\", 'IDP': f\"{ds_path}IDP_Results_Extension_{placeholder}wMoment.csv\"},\n",
    "    {'Name': 'LateralBending', 'ROM': f\"{ds_path}ROM_Results_LateralBending_{placeholder}wMoment.csv\", 'IDP': f\"{ds_path}IDP_Results_LateralBending_{placeholder}wMoment.csv\"},\n",
    "]\n",
    "\n",
    "input_file = ds_path + f\"MaterialConfigurations{\"_\" + placeholder[:-1] if len(placeholder) else \"\"}.csv\"\n",
    "bounds_file = ds_path + \"ParameterBounds.csv\"\n",
    "\n",
    "train_column_bounds = pd.read_csv(bounds_file)\n",
    "df = load_df(input_file, output_files)\n",
    "\n",
    "# normalize both input and output columns\n",
    "df, train_column_bounds = normalize_columns(df, column_bounds=train_column_bounds, train=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_id</th>\n",
       "      <th>LoadCase</th>\n",
       "      <th>Moment</th>\n",
       "      <th>C10Nucleus</th>\n",
       "      <th>C01Nucleus</th>\n",
       "      <th>C10Annulus</th>\n",
       "      <th>K1Annulus</th>\n",
       "      <th>K2Annulus</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>K1Circ</th>\n",
       "      <th>K2Circ</th>\n",
       "      <th>K1Rad</th>\n",
       "      <th>K2Rad</th>\n",
       "      <th>FiberAngle</th>\n",
       "      <th>FiberAngleCirc</th>\n",
       "      <th>FiberAngleRad</th>\n",
       "      <th>y_ROM</th>\n",
       "      <th>y_IDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029725</td>\n",
       "      <td>0.942940</td>\n",
       "      <td>0.664148</td>\n",
       "      <td>0.921854</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.259683</td>\n",
       "      <td>0.663973</td>\n",
       "      <td>0.062818</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.489396</td>\n",
       "      <td>0.239752</td>\n",
       "      <td>0.374661</td>\n",
       "      <td>0.971191</td>\n",
       "      <td>0.049952</td>\n",
       "      <td>0.523323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247972</td>\n",
       "      <td>0.942209</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>0.157741</td>\n",
       "      <td>0.202646</td>\n",
       "      <td>0.135846</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.858016</td>\n",
       "      <td>0.591501</td>\n",
       "      <td>0.994841</td>\n",
       "      <td>0.630346</td>\n",
       "      <td>0.474571</td>\n",
       "      <td>0.689127</td>\n",
       "      <td>0.093415</td>\n",
       "      <td>0.539389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635258</td>\n",
       "      <td>0.026542</td>\n",
       "      <td>0.809374</td>\n",
       "      <td>0.424060</td>\n",
       "      <td>0.456829</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.467026</td>\n",
       "      <td>0.574693</td>\n",
       "      <td>0.328489</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.189954</td>\n",
       "      <td>0.710109</td>\n",
       "      <td>0.066601</td>\n",
       "      <td>0.513135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.654910</td>\n",
       "      <td>0.704036</td>\n",
       "      <td>0.679229</td>\n",
       "      <td>0.608636</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.823352</td>\n",
       "      <td>0.712242</td>\n",
       "      <td>0.841573</td>\n",
       "      <td>0.131671</td>\n",
       "      <td>0.627868</td>\n",
       "      <td>0.832815</td>\n",
       "      <td>0.686986</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.519654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>0.389177</td>\n",
       "      <td>0.680306</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.828607</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.726765</td>\n",
       "      <td>0.897064</td>\n",
       "      <td>0.251119</td>\n",
       "      <td>0.632284</td>\n",
       "      <td>0.301170</td>\n",
       "      <td>0.700509</td>\n",
       "      <td>0.519569</td>\n",
       "      <td>0.068396</td>\n",
       "      <td>0.517184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.212410</td>\n",
       "      <td>0.577395</td>\n",
       "      <td>0.553552</td>\n",
       "      <td>0.950991</td>\n",
       "      <td>0.366432</td>\n",
       "      <td>0.461563</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>0.901203</td>\n",
       "      <td>0.310985</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>0.805681</td>\n",
       "      <td>0.514956</td>\n",
       "      <td>0.925940</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.603970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991926</td>\n",
       "      <td>0.131097</td>\n",
       "      <td>0.621420</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.745443</td>\n",
       "      <td>0.830001</td>\n",
       "      <td>0.827799</td>\n",
       "      <td>0.266717</td>\n",
       "      <td>0.953118</td>\n",
       "      <td>0.392787</td>\n",
       "      <td>0.768022</td>\n",
       "      <td>0.878251</td>\n",
       "      <td>0.530897</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>0.573318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.122382</td>\n",
       "      <td>0.503752</td>\n",
       "      <td>0.636114</td>\n",
       "      <td>0.917489</td>\n",
       "      <td>0.946015</td>\n",
       "      <td>0.747485</td>\n",
       "      <td>0.329838</td>\n",
       "      <td>0.152910</td>\n",
       "      <td>0.391322</td>\n",
       "      <td>0.132333</td>\n",
       "      <td>0.505382</td>\n",
       "      <td>0.916703</td>\n",
       "      <td>0.150653</td>\n",
       "      <td>0.462616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710095</td>\n",
       "      <td>0.058459</td>\n",
       "      <td>0.116247</td>\n",
       "      <td>0.230498</td>\n",
       "      <td>0.118430</td>\n",
       "      <td>0.438265</td>\n",
       "      <td>0.172031</td>\n",
       "      <td>0.072344</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0.182430</td>\n",
       "      <td>0.804260</td>\n",
       "      <td>0.812411</td>\n",
       "      <td>0.201419</td>\n",
       "      <td>0.132869</td>\n",
       "      <td>0.594048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209316</td>\n",
       "      <td>0.386496</td>\n",
       "      <td>0.690387</td>\n",
       "      <td>0.451169</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>0.955795</td>\n",
       "      <td>0.459343</td>\n",
       "      <td>0.949971</td>\n",
       "      <td>0.482256</td>\n",
       "      <td>0.669778</td>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.046922</td>\n",
       "      <td>0.434717</td>\n",
       "      <td>0.154046</td>\n",
       "      <td>0.520159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      config_id  LoadCase  Moment  C10Nucleus  C01Nucleus  C10Annulus  \\\n",
       "0             0       0.0     0.0    0.029725    0.942940    0.664148   \n",
       "1             1       0.0     0.0    0.247972    0.942209    0.018898   \n",
       "2             2       0.0     0.0    0.635258    0.026542    0.809374   \n",
       "3             3       0.0     0.0    0.952170    0.654910    0.704036   \n",
       "4             4       0.0     0.0    0.089696    0.389177    0.680306   \n",
       "...         ...       ...     ...         ...         ...         ...   \n",
       "1275         59       1.0     1.0    0.212410    0.577395    0.553552   \n",
       "1276         60       1.0     1.0    0.991926    0.131097    0.621420   \n",
       "1277         61       1.0     1.0    0.581443    0.122382    0.503752   \n",
       "1278         62       1.0     1.0    0.710095    0.058459    0.116247   \n",
       "1279         63       1.0     1.0    0.209316    0.386496    0.690387   \n",
       "\n",
       "      K1Annulus  K2Annulus     Kappa    K1Circ    K2Circ     K1Rad     K2Rad  \\\n",
       "0      0.921854   0.092080  0.259683  0.663973  0.062818  0.020170  0.489396   \n",
       "1      0.157741   0.202646  0.135846  0.026879  0.858016  0.591501  0.994841   \n",
       "2      0.424060   0.456829  0.003396  0.467026  0.574693  0.328489  0.009960   \n",
       "3      0.679229   0.608636  0.926893  0.823352  0.712242  0.841573  0.131671   \n",
       "4      0.043599   0.828607  0.000181  0.726765  0.897064  0.251119  0.632284   \n",
       "...         ...        ...       ...       ...       ...       ...       ...   \n",
       "1275   0.950991   0.366432  0.461563  0.216497  0.901203  0.310985  0.848445   \n",
       "1276   0.931875   0.745443  0.830001  0.827799  0.266717  0.953118  0.392787   \n",
       "1277   0.636114   0.917489  0.946015  0.747485  0.329838  0.152910  0.391322   \n",
       "1278   0.230498   0.118430  0.438265  0.172031  0.072344  0.136880  0.182430   \n",
       "1279   0.451169   0.288649  0.955795  0.459343  0.949971  0.482256  0.669778   \n",
       "\n",
       "      FiberAngle  FiberAngleCirc  FiberAngleRad     y_ROM     y_IDP  \n",
       "0       0.239752        0.374661       0.971191  0.049952  0.523323  \n",
       "1       0.630346        0.474571       0.689127  0.093415  0.539389  \n",
       "2       0.021167        0.189954       0.710109  0.066601  0.513135  \n",
       "3       0.627868        0.832815       0.686986  0.060443  0.519654  \n",
       "4       0.301170        0.700509       0.519569  0.068396  0.517184  \n",
       "...          ...             ...            ...       ...       ...  \n",
       "1275    0.805681        0.514956       0.925940  0.065768  0.603970  \n",
       "1276    0.768022        0.878251       0.530897  0.089262  0.573318  \n",
       "1277    0.132333        0.505382       0.916703  0.150653  0.462616  \n",
       "1278    0.804260        0.812411       0.201419  0.132869  0.594048  \n",
       "1279    0.756374        0.046922       0.434717  0.154046  0.520159  \n",
       "\n",
       "[1280 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = \"datasets/Test/\"\n",
    "output_files = [\n",
    "    {'Name': 'Flexion', 'ROM': ds_path + \"ROM_Results_Flexion_TestData_64_wMoment.csv\", 'IDP': ds_path + \"IDP_Results_Flexion_TestData_64_wMoment.csv\"},\n",
    "    {'Name': 'AxialRotation', 'ROM': ds_path + \"ROM_Results_AxialRotation_TestData_64_wMoment.csv\", 'IDP': ds_path + \"IDP_Results_AxialRotation_TestData_64_wMoment.csv\"},\n",
    "    {'Name': 'Extension', 'ROM': ds_path + \"ROM_Results_Extension_TestData_64_wMoment.csv\", 'IDP': ds_path + \"IDP_Results_Extension_TestData_64_wMoment.csv\"},\n",
    "    {'Name': 'LateralBending', 'ROM': ds_path + \"ROM_Results_LateralBending_TestData_64_wMoment.csv\", 'IDP': ds_path + \"IDP_Results_LateralBending_TestData_64_wMoment.csv\"},\n",
    "]\n",
    "input_file = ds_path + \"MaterialConfigurations_TestData_64.csv\"\n",
    "\n",
    "test_df = load_df(input_file, output_files)\n",
    "test_df = normalize_columns(test_df, column_bounds=train_column_bounds, train=False, keep_target=True)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try linear and non-linear ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression\n",
      "Load Case Flexion: Average MAE: 0.7231 (Std: 0.0179), Average R²: 0.7951 (Std: 0.0035)\n",
      "Load Case AxialRotation: Average MAE: 1.3170 (Std: 0.0218), Average R²: 0.4683 (Std: 0.0184)\n",
      "Load Case Extension: Average MAE: 1.2896 (Std: 0.0109), Average R²: 0.5070 (Std: 0.0134)\n",
      "Load Case LateralBending: Average MAE: 0.8772 (Std: 0.0254), Average R²: 0.4008 (Std: 0.0315)\n",
      "Average MAE: 1.0517 (Std: 0.2576), Average R²: 0.5428 (Std: 0.1505)\n",
      "Evaluating Random Forest\n",
      "Load Case Flexion: Average MAE: 0.4524 (Std: 0.0116), Average R²: 0.8984 (Std: 0.0068)\n",
      "Load Case AxialRotation: Average MAE: 0.6941 (Std: 0.0209), Average R²: 0.7855 (Std: 0.0229)\n",
      "Load Case Extension: Average MAE: 0.4761 (Std: 0.0329), Average R²: 0.9438 (Std: 0.0138)\n",
      "Load Case LateralBending: Average MAE: 0.2319 (Std: 0.0109), Average R²: 0.9408 (Std: 0.0043)\n",
      "Average MAE: 0.4636 (Std: 0.1636), Average R²: 0.8922 (Std: 0.0641)\n",
      "Evaluating SVR\n",
      "Load Case Flexion: Average MAE: 0.8748 (Std: 0.0193), Average R²: 0.7125 (Std: 0.0118)\n",
      "Load Case AxialRotation: Average MAE: 1.0231 (Std: 0.0386), Average R²: 0.6726 (Std: 0.0185)\n",
      "Load Case Extension: Average MAE: 1.1888 (Std: 0.0327), Average R²: 0.7723 (Std: 0.0053)\n",
      "Load Case LateralBending: Average MAE: 0.8162 (Std: 0.0628), Average R²: 0.4399 (Std: 0.0602)\n",
      "Average MAE: 0.9757 (Std: 0.1443), Average R²: 0.6493 (Std: 0.1260)\n",
      "Evaluating LightGBM\n",
      "Load Case Flexion: Average MAE: 0.3198 (Std: 0.0173), Average R²: 0.9489 (Std: 0.0054)\n",
      "Load Case AxialRotation: Average MAE: 0.4365 (Std: 0.0261), Average R²: 0.9199 (Std: 0.0131)\n",
      "Load Case Extension: Average MAE: 0.3832 (Std: 0.0190), Average R²: 0.9616 (Std: 0.0080)\n",
      "Load Case LateralBending: Average MAE: 0.2032 (Std: 0.0090), Average R²: 0.9516 (Std: 0.0062)\n",
      "Average MAE: 0.3357 (Std: 0.0869), Average R²: 0.9455 (Std: 0.0155)\n",
      "Evaluating GP\n",
      "Load Case Flexion: Average MAE: 0.4030 (Std: 0.0232), Average R²: 0.9180 (Std: 0.0110)\n",
      "Load Case AxialRotation: Average MAE: 0.4969 (Std: 0.0220), Average R²: 0.9123 (Std: 0.0068)\n",
      "Load Case Extension: Average MAE: 0.5385 (Std: 0.0300), Average R²: 0.9282 (Std: 0.0062)\n",
      "Load Case LateralBending: Average MAE: 0.3007 (Std: 0.0138), Average R²: 0.9081 (Std: 0.0078)\n",
      "Average MAE: 0.4348 (Std: 0.0917), Average R²: 0.9167 (Std: 0.0075)\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['y_ROM']\n",
    "eval_validation = False\n",
    "'''\n",
    "# Small dataset\n",
    "gp_kernel = C(constant_value=1e-05,constant_value_bounds=\"fixed\") * RBF(length_scale=1.4270972012234615, length_scale_bounds=\"fixed\" )\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=14, n_estimators= 121, random_state=random_state),\n",
    "    \"SVR\": SVR(C=96.81294212057983, gamma='scale', kernel= 'rbf'),\n",
    "    #\"Gradient Boosting\": GradientBoostingRegressor(n_estimators=185, learning_rate=0.3214585218102217, max_depth=5, random_state=random_state),\n",
    "    #\"XGBoost\": xgb.XGBRegressor(n_estimators=198, max_depth=5, learning_rate=0.3165429507603652, random_state=random_state),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=random_state, verbose=-1),\n",
    "    \"GP\": GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=0, normalize_y=True, random_state=random_state),\n",
    "}\n",
    "\n",
    "'''\n",
    "# Medium dataset\n",
    "gp_kernel = C(constant_value=1e-05,constant_value_bounds=\"fixed\") * RBF(length_scale=1.4270972012234615, length_scale_bounds=\"fixed\" )\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=26, n_estimators=146, random_state=random_state),\n",
    "    \"SVR\": SVR(C=13.171289753772092, gamma=\"scale\", kernel=\"rbf\"),\n",
    "    #\"Gradient Boosting\": GradientBoostingRegressor(n_estimators= 141, learning_rate=0.14233612312010724, max_depth=6, random_state=random_state),\n",
    "    #\"XGBoost\": xgb.XGBRegressor(n_estimators=173, max_depth=6, learning_rate=0.11597899680228448, random_state=random_state),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(num_leaves=31, max_depth=8, learning_rate=0.11036437743275099, n_estimators=173, random_state=random_state, verbose=-1),\n",
    "    \"GP\": GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=0, normalize_y=True, random_state=random_state),\n",
    "}\n",
    "'''\n",
    "# Large dataset\n",
    "gp_kernel = C(constant_value=1.3535458162698054e-05,constant_value_bounds=\"fixed\") * RBF(length_scale=0.9739157609228299, length_scale_bounds=\"fixed\" )\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=31, n_estimators=51, random_state=random_state),\n",
    "    \"SVR\": SVR(C=2.479459357922161, gamma=\"auto\", kernel=\"rbf\"),\n",
    "    #\"Gradient Boosting\": GradientBoostingRegressor(n_estimators= 84, learning_rate= 0.17251713060020465, max_depth=7, random_state=random_state),\n",
    "    #\"XGBoost\": xgb.XGBRegressor(n_estimators=179, max_depth=6, learning_rate= 0.11678452806022886, random_state=random_state),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(num_leaves=71, max_depth=24, learning_rate=0.0959080973897064, n_estimators=183, random_state=random_state, verbose=-1),\n",
    "    \"GP\": GaussianProcessRegressor(kernel=gp_kernel, n_restarts_optimizer=0, normalize_y=True, random_state=random_state),\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, X_val, y_train, y_val, bounds=None):\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    if bounds is not None:\n",
    "        predictions = predictions * (bounds['y_ROM']['max'] - bounds['y_ROM']['min']) + bounds['y_ROM']['min']\n",
    "        y_val = y_val * (bounds['y_ROM']['max'] - bounds['y_ROM']['min']) + bounds['y_ROM']['min']\n",
    "\n",
    "    #mse = mean_squared_error(y_val, predictions)\n",
    "    #mae = mean_absolute_error(y_val, predictions)\n",
    "    #r2 = r2_score(y_val, predictions)\n",
    "\n",
    "    lc_r2 = []\n",
    "    lc_mae = []\n",
    "    for load_case in test_df['LoadCase'].unique():\n",
    "        mask = test_df['LoadCase'] == load_case\n",
    "        lc_r2.append(r2_score(y_val[mask], predictions[mask]))\n",
    "        lc_mae.append(mean_absolute_error(y_val[mask], predictions[mask]))\n",
    "\n",
    "    return lc_r2, lc_mae\n",
    "\n",
    "# KFold cross-validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}\")\n",
    "    scores = {score: list() for score in ['mse', 'mae', 'r2']}\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(df['config_id'].unique())):\n",
    "        # get values by id\n",
    "        df_train = df[df['config_id'].isin(train_index)]\n",
    "        df_val = df[df['config_id'].isin(val_index)]\n",
    "\n",
    "        X_train, X_val, X_test = df_train.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1), df_val.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1), test_df.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1),\n",
    "        y_train, y_val, y_test = df_train[target_columns] , df_val[target_columns], test_df[target_columns]\n",
    "\n",
    "        if eval_validation:\n",
    "            lc_r2, lc_mae = train_and_evaluate(model, X_train, X_val, y_train, y_val)\n",
    "        else:\n",
    "            lc_r2, lc_mae = train_and_evaluate(model, X_train, X_test, y_train, y_test, bounds=train_column_bounds)\n",
    "            \n",
    "\n",
    "        scores['mae'].append(lc_mae)\n",
    "        scores['r2'].append(lc_r2)\n",
    "\n",
    "    # compute average and std per load case for R2 and MAE scores\n",
    "    scores['mae'] = np.array(scores['mae'])\n",
    "    scores['r2'] = np.array(scores['r2'])\n",
    "    lc_mae_means = list()\n",
    "    lc_r2_means = list()\n",
    "    for i, lc in enumerate(LoadCases):\n",
    "        lc_mae_mean = np.mean(scores['mae'][:, i])\n",
    "        lc_r2_mean = np.mean(scores['r2'][:, i])\n",
    "        \n",
    "        lc_mae_means.append(lc_mae_mean)\n",
    "        lc_r2_means.append(lc_r2_mean)\n",
    "        \n",
    "        print(f\"Load Case {lc}: Average MAE: {lc_mae_mean:.4f} (Std: {np.std(scores['mae'][:, i]):.4f}), Average R²: {lc_r2_mean:.4f} (Std: {np.std(scores['r2'][:, i]):.4f})\")\n",
    "\n",
    "    # Compute average and std acroos and load cases for R2 and MAE scores\n",
    "    mae_mean = np.mean(lc_mae_means)\n",
    "    mae_std = np.std(lc_mae_means)\n",
    "    r2_mean = np.mean(lc_r2_means)\n",
    "    r2_std = np.std(lc_r2_means)\n",
    "    print(f\"Average MAE: {mae_mean:.4f} (Std: {mae_std:.4f}), Average R²: {r2_mean:.4f} (Std: {r2_std:.4f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/300 [00:38<01:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, fold 0 epoch 80\n",
      "Load Case Flexion: Average MAE: 0.1443 (Std: 0.0000), Average R²: 0.9898 (Std: 0.0000)\n",
      "Load Case AxialRotation: Average MAE: 0.1918 (Std: 0.0000), Average R²: 0.9847 (Std: 0.0000)\n",
      "Load Case Extension: Average MAE: 0.1553 (Std: 0.0000), Average R²: 0.9906 (Std: 0.0000)\n",
      "Load Case LateralBending: Average MAE: 0.0888 (Std: 0.0000), Average R²: 0.9895 (Std: 0.0000)\n",
      "Average MAE: 0.1451 (Std: 0.0370), Average R²: 0.9886 (Std: 0.0023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['y_ROM']\n",
    "\n",
    "\n",
    "# Small dataset\n",
    "hparams = {\n",
    "    'input_dim': 15,\n",
    "    'output_dim': len(target_columns),\n",
    "    'activation': 'relu',\n",
    "    'num_units': 128, \n",
    "    'num_layers': 5, \n",
    "    'batch_size': 14, \n",
    "    'num_epochs': 231, \n",
    "    'lr': 0.0005598762669544375, \n",
    "    'weight_decay': 0.0005164420694702161, \n",
    "    'early_stopping_patience': 26,\n",
    "    'dropout_p': 0.01, \n",
    "}\n",
    "# Large and Medium dataset\n",
    "hparams.update({'num_units': 256, \n",
    "                'num_layers': 5, \n",
    "                'batch_size': 20, \n",
    "                'num_epochs': 300, \n",
    "                'lr': 0.0005555051127271821, \n",
    "                'weight_decay': 5.162935106110616e-06, \n",
    "                'early_stopping_patience': 23,\n",
    "                })\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "\n",
    "fold = 0\n",
    "scores = {score: list() for score in ['mae', 'r2']}\n",
    "trained_models = list()\n",
    "for train_index, val_index in kf.split(df['config_id'].unique()):\n",
    "    df_train = df[df['config_id'].isin(train_index)]\n",
    "    df_val = df[df['config_id'].isin(val_index)]\n",
    "\n",
    "    X_train, X_val, X_test = df_train.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1), df_val.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1), test_df.drop(['config_id', 'y_ROM', 'y_IDP'], axis=1)\n",
    "    y_train, y_val, y_test = df_train[target_columns], df_val[target_columns], test_df[target_columns]\n",
    "\n",
    "    # Converting to PyTorch tensors\n",
    "    X_train_torch = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_val_torch = torch.tensor(X_val.values, dtype=torch.float32, device=device)\n",
    "    X_test_torch = torch.tensor(X_test.values, dtype=torch.float32, device=device)\n",
    "    y_train_torch = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "    # Creating datasets and dataloaders\n",
    "    train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "\n",
    "    # Model, loss function, and optimizer\n",
    "    nn_model = RegressionNet(hparams)\n",
    "    nn_model.to(device)\n",
    "    criterion = nn.MSELoss() #nn.L1Loss()\n",
    "    optimizer = optim.Adam(nn_model.parameters(), lr=hparams['lr'], weight_decay=hparams['weight_decay'])\n",
    "\n",
    "    # Early stopping parameters\n",
    "    best_mae = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    fold_train_loss, fold_val_loss = list(), list()\n",
    "    for epoch in tqdm(range(hparams['num_epochs'])):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        # Training the model\n",
    "        nn_model.train()\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = nn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)  # Multiply by batch size\n",
    "            num_batches += inputs.size(0)\n",
    "        \n",
    "        average_loss = total_loss / num_batches\n",
    "        fold_train_loss.append(average_loss)\n",
    "        \n",
    "        # Evaluating the model\n",
    "        nn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = nn_model(X_val_torch)\n",
    "            mae = mean_absolute_error(y_val, predictions.cpu().numpy())\n",
    "            fold_val_loss.append(mae)\n",
    "\n",
    "        # Check for improvement\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= hparams['early_stopping_patience']:\n",
    "            print(\"Early stopping, fold %d epoch %d\" % (fold, epoch))\n",
    "            break  # Early stopping\n",
    "\n",
    "        nn_model.train()\n",
    "    \n",
    "    # Evaluating the model\n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():  \n",
    "        predictions = nn_model(X_test_torch).cpu().numpy()\n",
    "        predictions = predictions * (train_column_bounds['y_ROM']['max'] - train_column_bounds['y_ROM']['min']) + train_column_bounds['y_ROM']['min']\n",
    "        y_test = y_test * (train_column_bounds['y_ROM']['max'] - train_column_bounds['y_ROM']['min']) + train_column_bounds['y_ROM']['min']\n",
    "\n",
    "    lc_r2 = []\n",
    "    lc_mae = []\n",
    "    for load_case in test_df['LoadCase'].unique():\n",
    "        mask = test_df['LoadCase'] == load_case\n",
    "        lc_r2.append(r2_score(y_test[mask], predictions[mask]))\n",
    "        lc_mae.append(mean_absolute_error(y_test[mask], predictions[mask]))\n",
    "\n",
    "    scores['mae'].append(lc_mae)\n",
    "    scores['r2'].append(lc_r2)\n",
    "    trained_models.append(nn_model)\n",
    "    fold += 1 \n",
    "    break\n",
    "\n",
    "scores['mae'] = np.array(scores['mae'])\n",
    "scores['r2'] = np.array(scores['r2'])\n",
    "lc_mae_means = list()\n",
    "lc_r2_means = list()\n",
    "for i, lc in enumerate(LoadCases):\n",
    "    lc_mae_mean = np.mean(scores['mae'][:, i])\n",
    "    lc_r2_mean = np.mean(scores['r2'][:, i])\n",
    "    \n",
    "    lc_mae_means.append(lc_mae_mean)\n",
    "    lc_r2_means.append(lc_r2_mean)\n",
    "    \n",
    "    print(f\"Load Case {lc}: Average MAE: {lc_mae_mean:.4f} (Std: {np.std(scores['mae'][:, i]):.4f}), Average R²: {lc_r2_mean:.4f} (Std: {np.std(scores['r2'][:, i]):.4f})\")\n",
    "\n",
    "# Compute average and std acroos and load cases for R2 and MAE scores\n",
    "mae_mean = np.mean(lc_mae_means)\n",
    "mae_std = np.std(lc_mae_means)\n",
    "r2_mean = np.mean(lc_r2_means)\n",
    "r2_std = np.std(lc_r2_means)\n",
    "print(f\"Average MAE: {mae_mean:.4f} (Std: {mae_std:.4f}), Average R²: {r2_mean:.4f} (Std: {r2_std:.4f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Hyperparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['y_ROM']\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "criterion = nn.L1Loss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def search_objective(trial):\n",
    "    # Hyperparameters to tune  \n",
    "    num_units = trial.suggest_categorical('num_units', [128, 256, 512, 1024])\n",
    "    num_layers = trial.suggest_categorical('num_layers', [4, 5, 6, 7, 8, ])\n",
    "    batch_size = trial.suggest_int('batch_size', 12, 64)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 150, 500)\n",
    "    lr = trial.suggest_float('lr', 1e-6, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "    dropout_p = 0 #trial.suggest_categorical('dropout_p', [0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    early_stopping_patience = trial.suggest_int('early_stopping_patience', 5, 30)\n",
    "\n",
    "    hparams = {\n",
    "        'input_dim': len(df.columns) - len(target_columns) - 1,\n",
    "        'output_dim': len(target_columns),\n",
    "        'num_units': num_units, \n",
    "        'num_layers': num_layers, \n",
    "        'batch_size': batch_size, \n",
    "        'num_epochs': num_epochs, \n",
    "        'lr': lr, \n",
    "        'weight_decay': weight_decay, \n",
    "        'dropout_p': dropout_p, \n",
    "        'early_stopping_patience': early_stopping_patience,\n",
    "    }\n",
    "    \n",
    "    mae_scores = list()\n",
    "    fold_id = 0\n",
    "    for train_index, test_index in kf.split(df['config_id'].unique()):\n",
    "        df_train = df[df['config_id'].isin(train_index)]\n",
    "        df_test = df[df['config_id'].isin(test_index)]\n",
    "\n",
    "        X_train, X_test = df_train.drop(['config_id'] + target_columns, axis=1), df_test.drop(['config_id'] + target_columns, axis=1)\n",
    "        y_train, y_test = df_train[target_columns], df_test[target_columns]\n",
    "\n",
    "        # Converting to PyTorch tensors\n",
    "        X_train_torch = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_torch = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "        X_test_torch = torch.tensor(X_test.values, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Creating datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Update the model with new hyperparameters\n",
    "        nn_model = RegressionNet(hparams)\n",
    "        nn_model.to(device)\n",
    "        optimizer = optim.Adam(nn_model.parameters(), lr=hparams['lr'], weight_decay=hparams['weight_decay'])\n",
    "\n",
    "        # Early stopping parameters\n",
    "        best_mae = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Training the model\n",
    "        for epoch in tqdm(range(hparams['num_epochs'])):\n",
    "            epoch_loss = 0.0\n",
    "            nn_model.train()\n",
    "            for data in train_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = nn_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # Average loss for the epoch\n",
    "            epoch_loss /= len(train_loader)\n",
    "\n",
    "            # Evaluating the model\n",
    "            nn_model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions = nn_model(X_test_torch)\n",
    "                mae = mean_absolute_error(y_test, predictions.cpu().numpy())\n",
    "\n",
    "            # Check for improvement\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            \n",
    "            if epochs_no_improve >= hparams['early_stopping_patience']:\n",
    "                break  # Early stopping\n",
    "            \n",
    "        mae_scores.append(best_mae)\n",
    "        #fold_id += 1\n",
    "        # a single fold to speed up\n",
    "        break\n",
    "\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    return avg_mae # Optuna min the objective\n",
    "\n",
    "pruner = MedianPruner()\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "\n",
    "# Execute an optimization\n",
    "study.optimize(search_objective, n_trials=80, show_progress_bar=True)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.values, study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP Search Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: [429.5514931978272, 0.6554197303387509]\n",
      "Best mean squared error: 0.0010438637464197948\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['y_ROM']\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "for train_index, test_index in kf.split(df['config_id'].unique()):\n",
    "    df_train = df[df['config_id'].isin(train_index)]\n",
    "    df_test = df[df['config_id'].isin(test_index)]\n",
    "    X_train, X_test = df_train.drop(['config_id'] + target_columns, axis=1), df_test.drop(['config_id'] + target_columns, axis=1)\n",
    "    y_train, y_test = df_train[target_columns], df_test[target_columns]\n",
    "    break\n",
    "\n",
    "# Define the space of hyperparameters to optimize\n",
    "space  = [\n",
    "    Real(1e-5, 1e3, \"log-uniform\", name='kernel__k1__constant_value'),\n",
    "    Real(1e-3, 1e3, \"log-uniform\", name='kernel__k2__length_scale')\n",
    "]\n",
    "\n",
    "# Define the kernel using hyperparameters\n",
    "def create_model(params):\n",
    "    kernel = C(constant_value=params[\"kernel__k1__constant_value\"], constant_value_bounds=\"fixed\") \\\n",
    "        * RBF(length_scale=params['kernel__k2__length_scale'], length_scale_bounds=\"fixed\")\n",
    "\n",
    "    return GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=0, normalize_y=True)\n",
    "\n",
    "# Define the objective function to minimize\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model = create_model(params)\n",
    "    model.fit(X_train, y_train)  # Assuming X_train and y_train are predefined\n",
    "    # Calculate the mean squared error on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse  # We minimize MSE directly\n",
    "\n",
    "# Perform optimization\n",
    "result = gp_minimize(objective, space, n_calls=50, random_state=random_state)\n",
    "\n",
    "# Print the best found parameters and the corresponding value of the objective function\n",
    "print(\"Best parameters:\", result.x)\n",
    "print(\"Best mean squared error:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-13 13:45:06,696] A new study created in memory with name: no-name-772a9c2b-a5e8-4857-8134-771639cb88ff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:10,759] Trial 0 finished with value: 0.029189352853743626 and parameters: {'max_depth': 14, 'n_estimators': 63}. Best is trial 0 with value: 0.029189352853743626.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:15,654] Trial 1 finished with value: 0.02873982077103532 and parameters: {'max_depth': 23, 'n_estimators': 68}. Best is trial 1 with value: 0.02873982077103532.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:16,063] Trial 2 finished with value: 0.04503602713349913 and parameters: {'max_depth': 7, 'n_estimators': 12}. Best is trial 1 with value: 0.02873982077103532.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:17,205] Trial 3 finished with value: 0.07951072126978105 and parameters: {'max_depth': 2, 'n_estimators': 127}. Best is trial 1 with value: 0.02873982077103532.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:18,566] Trial 4 finished with value: 0.03038264535064492 and parameters: {'max_depth': 12, 'n_estimators': 24}. Best is trial 1 with value: 0.02873982077103532.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:22,532] Trial 5 finished with value: 0.0287100667207989 and parameters: {'max_depth': 23, 'n_estimators': 55}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:28,143] Trial 6 finished with value: 0.02882223540038514 and parameters: {'max_depth': 32, 'n_estimators': 78}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:37,447] Trial 7 finished with value: 0.02890279811867883 and parameters: {'max_depth': 19, 'n_estimators': 131}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:45,827] Trial 8 finished with value: 0.028765578922533154 and parameters: {'max_depth': 26, 'n_estimators': 117}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:45:47,357] Trial 9 finished with value: 0.0712727973452902 and parameters: {'max_depth': 3, 'n_estimators': 110}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:00,837] Trial 10 finished with value: 0.028801143187545414 and parameters: {'max_depth': 31, 'n_estimators': 188}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:04,790] Trial 11 finished with value: 0.028897698036103807 and parameters: {'max_depth': 21, 'n_estimators': 55}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:08,006] Trial 12 finished with value: 0.02893837876266109 and parameters: {'max_depth': 25, 'n_estimators': 45}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:14,171] Trial 13 finished with value: 0.028786559867876958 and parameters: {'max_depth': 24, 'n_estimators': 86}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:16,702] Trial 14 finished with value: 0.029207289855111635 and parameters: {'max_depth': 16, 'n_estimators': 37}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:27,778] Trial 15 finished with value: 0.028740027595743664 and parameters: {'max_depth': 28, 'n_estimators': 155}. Best is trial 5 with value: 0.0287100667207989.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:34,370] Trial 16 finished with value: 0.02869919993837572 and parameters: {'max_depth': 20, 'n_estimators': 93}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:40,939] Trial 17 finished with value: 0.028898706257214333 and parameters: {'max_depth': 19, 'n_estimators': 93}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:48,419] Trial 18 finished with value: 0.033212543037704524 and parameters: {'max_depth': 10, 'n_estimators': 158}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:54,572] Trial 19 finished with value: 0.028919467061756802 and parameters: {'max_depth': 16, 'n_estimators': 91}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:46:57,216] Trial 20 finished with value: 0.0290480513814356 and parameters: {'max_depth': 29, 'n_estimators': 37}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:02,119] Trial 21 finished with value: 0.028887488971018466 and parameters: {'max_depth': 22, 'n_estimators': 69}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:06,474] Trial 22 finished with value: 0.028820230946813564 and parameters: {'max_depth': 22, 'n_estimators': 61}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:13,293] Trial 23 finished with value: 0.028857314668606245 and parameters: {'max_depth': 18, 'n_estimators': 97}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:18,579] Trial 24 finished with value: 0.028817551967489835 and parameters: {'max_depth': 23, 'n_estimators': 74}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:21,754] Trial 25 finished with value: 0.028943074875447197 and parameters: {'max_depth': 27, 'n_estimators': 44}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:29,441] Trial 26 finished with value: 0.028736294418289596 and parameters: {'max_depth': 20, 'n_estimators': 108}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:39,599] Trial 27 finished with value: 0.028765178612858124 and parameters: {'max_depth': 20, 'n_estimators': 143}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:46,617] Trial 28 finished with value: 0.029132975209619043 and parameters: {'max_depth': 15, 'n_estimators': 107}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:54,148] Trial 29 finished with value: 0.02960443404199085 and parameters: {'max_depth': 13, 'n_estimators': 126}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:47:59,871] Trial 30 finished with value: 0.028822116658323262 and parameters: {'max_depth': 17, 'n_estimators': 83}. Best is trial 16 with value: 0.02869919993837572.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:04,009] Trial 31 finished with value: 0.028684241228678742 and parameters: {'max_depth': 24, 'n_estimators': 58}. Best is trial 31 with value: 0.028684241228678742.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:07,858] Trial 32 finished with value: 0.028804270113980863 and parameters: {'max_depth': 25, 'n_estimators': 54}. Best is trial 31 with value: 0.028684241228678742.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:09,362] Trial 33 finished with value: 0.029124495789885622 and parameters: {'max_depth': 21, 'n_estimators': 21}. Best is trial 31 with value: 0.028684241228678742.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:16,643] Trial 34 finished with value: 0.028788280455272795 and parameters: {'max_depth': 29, 'n_estimators': 102}. Best is trial 31 with value: 0.028684241228678742.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:21,141] Trial 35 finished with value: 0.028622934556073405 and parameters: {'max_depth': 24, 'n_estimators': 63}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:25,914] Trial 36 finished with value: 0.02872572329774198 and parameters: {'max_depth': 23, 'n_estimators': 67}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:27,568] Trial 37 finished with value: 0.029054458332710493 and parameters: {'max_depth': 26, 'n_estimators': 23}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:31,646] Trial 38 finished with value: 0.02864531035455338 and parameters: {'max_depth': 30, 'n_estimators': 57}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:32,518] Trial 39 finished with value: 0.029651466233221978 and parameters: {'max_depth': 29, 'n_estimators': 12}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:38,237] Trial 40 finished with value: 0.028813100175092542 and parameters: {'max_depth': 31, 'n_estimators': 80}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:42,245] Trial 41 finished with value: 0.02865964538764542 and parameters: {'max_depth': 27, 'n_estimators': 56}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:45,535] Trial 42 finished with value: 0.028814158026463182 and parameters: {'max_depth': 27, 'n_estimators': 46}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:49,893] Trial 43 finished with value: 0.028668226422658587 and parameters: {'max_depth': 30, 'n_estimators': 61}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:52,258] Trial 44 finished with value: 0.02906884835856528 and parameters: {'max_depth': 32, 'n_estimators': 33}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:48:56,400] Trial 45 finished with value: 0.028660528245618638 and parameters: {'max_depth': 30, 'n_estimators': 58}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:49:01,551] Trial 46 finished with value: 0.028790782427548456 and parameters: {'max_depth': 30, 'n_estimators': 72}. Best is trial 35 with value: 0.028622934556073405.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:49:05,197] Trial 47 finished with value: 0.028622639140881322 and parameters: {'max_depth': 31, 'n_estimators': 51}. Best is trial 47 with value: 0.028622639140881322.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:49:08,835] Trial 48 finished with value: 0.028622639140881322 and parameters: {'max_depth': 32, 'n_estimators': 51}. Best is trial 47 with value: 0.028622639140881322.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-05-13 13:49:12,279] Trial 49 finished with value: 0.028657124200648802 and parameters: {'max_depth': 32, 'n_estimators': 48}. Best is trial 47 with value: 0.028622639140881322.\n",
      "[I 2024-05-13 13:49:12,279] A new study created in memory with name: no-name-967c4c46-17ce-4909-b1e6-accb68932116\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:12,792] Trial 0 finished with value: 0.055350314351851455 and parameters: {'C': 21.270787966204434, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 0 with value: 0.055350314351851455.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:13,132] Trial 1 finished with value: 0.05840213348010696 and parameters: {'C': 0.12994495185000887, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 0 with value: 0.055350314351851455.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:13,458] Trial 2 finished with value: 0.057749548952212675 and parameters: {'C': 0.16419365289407392, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 0 with value: 0.055350314351851455.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:13,827] Trial 3 finished with value: 0.05907870524745084 and parameters: {'C': 0.4059852741345588, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 0 with value: 0.055350314351851455.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:14,166] Trial 4 finished with value: 0.053351602744671774 and parameters: {'C': 5.9298781179817635, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 4 with value: 0.053351602744671774.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:14,497] Trial 5 finished with value: 0.06053319857434285 and parameters: {'C': 17.358541251327125, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 4 with value: 0.053351602744671774.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:14,789] Trial 6 finished with value: 0.052986854740022016 and parameters: {'C': 1.5957345721293812, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:15,162] Trial 7 finished with value: 0.05931978452381077 and parameters: {'C': 50.97525466232388, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:49:15,557] Trial 8 finished with value: 0.05928883097125118 and parameters: {'C': 57.631324201936295, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:38,456] Trial 9 finished with value: 0.09565211582415936 and parameters: {'C': 47.33668538498062, 'gamma': 'scale', 'kernel': 'poly'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:38,913] Trial 10 finished with value: 0.059123174778866784 and parameters: {'C': 0.8996057546821523, 'gamma': 'scale', 'kernel': 'linear'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:39,145] Trial 11 finished with value: 0.05782296463000666 and parameters: {'C': 3.975119676782414, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 6 with value: 0.052986854740022016.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:39,451] Trial 12 finished with value: 0.05288055725842988 and parameters: {'C': 3.1323953451920707, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:39,741] Trial 13 finished with value: 0.05322436635284553 and parameters: {'C': 1.2075140807919396, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:40,031] Trial 14 finished with value: 0.05335297596577761 and parameters: {'C': 1.0873920333130214, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:40,251] Trial 15 finished with value: 0.05668240543829929 and parameters: {'C': 7.8915250506952725, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:40,934] Trial 16 finished with value: 0.059132690404246346 and parameters: {'C': 2.2526543982001295, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:41,241] Trial 17 finished with value: 0.056121524856555575 and parameters: {'C': 0.37508342023887764, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:41,480] Trial 18 finished with value: 0.05769776088659677 and parameters: {'C': 2.480943659331419, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:43,172] Trial 19 finished with value: 0.05913598631966082 and parameters: {'C': 10.176533040975496, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:43,465] Trial 20 finished with value: 0.05447362893937082 and parameters: {'C': 0.7002262669532542, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:43,758] Trial 21 finished with value: 0.053043503246134556 and parameters: {'C': 1.514933003291869, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:44,053] Trial 22 finished with value: 0.05288873031586942 and parameters: {'C': 1.8708820614411685, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:44,362] Trial 23 finished with value: 0.05298553099166068 and parameters: {'C': 3.4028103622480756, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:44,675] Trial 24 finished with value: 0.05329424656301854 and parameters: {'C': 4.201173443143089, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 12 with value: 0.05288055725842988.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:44,981] Trial 25 finished with value: 0.052763321554916545 and parameters: {'C': 2.809529948393792, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:45,273] Trial 26 finished with value: 0.054843494140368966 and parameters: {'C': 0.6033993783862752, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:45,509] Trial 27 finished with value: 0.057831113186003015 and parameters: {'C': 2.1281301065994547, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:47,790] Trial 28 finished with value: 0.059111833930541355 and parameters: {'C': 15.53737534535278, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:48,149] Trial 29 finished with value: 0.060212049390600215 and parameters: {'C': 28.77391777120637, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:48,521] Trial 30 finished with value: 0.0538678843889911 and parameters: {'C': 9.351610860031837, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:48,836] Trial 31 finished with value: 0.053341173011541884 and parameters: {'C': 4.350251366761877, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:49,140] Trial 32 finished with value: 0.05290212645781005 and parameters: {'C': 3.1930084267305787, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:49,477] Trial 33 finished with value: 0.05336470659098501 and parameters: {'C': 6.155241897971703, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 25 with value: 0.052763321554916545.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:49,778] Trial 34 finished with value: 0.05270982665120055 and parameters: {'C': 2.6049556374793883, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:50,095] Trial 35 finished with value: 0.05646326868619424 and parameters: {'C': 0.28396535149258245, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:50,893] Trial 36 finished with value: 0.05635259843700205 and parameters: {'C': 95.66738460564714, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:51,187] Trial 37 finished with value: 0.052934553006112196 and parameters: {'C': 1.7293617662337766, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:51,513] Trial 38 finished with value: 0.05343148766751392 and parameters: {'C': 5.31100356836443, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:51,899] Trial 39 finished with value: 0.07179050505458205 and parameters: {'C': 0.10791667474076139, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:52,315] Trial 40 finished with value: 0.05915356783664305 and parameters: {'C': 0.605797609870893, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 34 with value: 0.05270982665120055.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:52,617] Trial 41 finished with value: 0.052705914861852464 and parameters: {'C': 2.536613749368092, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 41 with value: 0.052705914861852464.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:52,915] Trial 42 finished with value: 0.052679846262782236 and parameters: {'C': 2.479459357922161, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:53,218] Trial 43 finished with value: 0.05278642811296065 and parameters: {'C': 2.8346400387732236, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:53,521] Trial 44 finished with value: 0.052775073447488954 and parameters: {'C': 2.752022477790048, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:53,765] Trial 45 finished with value: 0.058046389471283696 and parameters: {'C': 1.4125057482134464, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:54,084] Trial 46 finished with value: 0.06186467951116346 and parameters: {'C': 6.423173069035968, 'gamma': 'auto', 'kernel': 'poly'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:54,375] Trial 47 finished with value: 0.05368701019856483 and parameters: {'C': 0.9679637530094648, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:54,760] Trial 48 finished with value: 0.054321838610373305 and parameters: {'C': 11.238621433707605, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "/tmp/ipykernel_1154580/489505884.py:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2024-05-13 13:51:55,002] Trial 49 finished with value: 0.057715943709865714 and parameters: {'C': 2.398714651870453, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 42 with value: 0.052679846262782236.\n",
      "[I 2024-05-13 13:51:55,002] A new study created in memory with name: no-name-8d08f7e4-9507-46df-bd63-e3e825239f2f\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:51:55,859] Trial 0 finished with value: 0.051488259239015254 and parameters: {'n_estimators': 18, 'learning_rate': 0.062216057711383665, 'max_depth': 7}. Best is trial 0 with value: 0.051488259239015254.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:51:58,013] Trial 1 finished with value: 0.028355409745206624 and parameters: {'n_estimators': 56, 'learning_rate': 0.49295583529780146, 'max_depth': 7}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:01,696] Trial 2 finished with value: 0.04425991829967938 and parameters: {'n_estimators': 55, 'learning_rate': 0.3492747418341074, 'max_depth': 28}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:06,916] Trial 3 finished with value: 0.030296455356714307 and parameters: {'n_estimators': 86, 'learning_rate': 0.40933231484472715, 'max_depth': 11}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:09,991] Trial 4 finished with value: 0.044575151643584866 and parameters: {'n_estimators': 112, 'learning_rate': 0.40174860272371354, 'max_depth': 29}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:17,038] Trial 5 finished with value: 0.03966395824688796 and parameters: {'n_estimators': 84, 'learning_rate': 0.4174263716847225, 'max_depth': 15}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:29,465] Trial 6 finished with value: 0.037123235224020126 and parameters: {'n_estimators': 162, 'learning_rate': 0.4163114679842151, 'max_depth': 14}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:48,431] Trial 7 finished with value: 0.0435553872208136 and parameters: {'n_estimators': 181, 'learning_rate': 0.048235370473723366, 'max_depth': 26}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:50,648] Trial 8 finished with value: 0.06398028839153384 and parameters: {'n_estimators': 47, 'learning_rate': 0.015092855225395106, 'max_depth': 7}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:53,334] Trial 9 finished with value: 0.043218277410115226 and parameters: {'n_estimators': 200, 'learning_rate': 0.4459192875620743, 'max_depth': 25}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:52:55,729] Trial 10 finished with value: 0.03178083583208469 and parameters: {'n_estimators': 143, 'learning_rate': 0.19458084855226643, 'max_depth': 3}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:00,945] Trial 11 finished with value: 0.03054547078569317 and parameters: {'n_estimators': 96, 'learning_rate': 0.4942807532369222, 'max_depth': 10}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:05,464] Trial 12 finished with value: 0.043661500981558035 and parameters: {'n_estimators': 62, 'learning_rate': 0.2930305984099325, 'max_depth': 19}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:05,694] Trial 13 finished with value: 0.05507322965091362 and parameters: {'n_estimators': 13, 'learning_rate': 0.19667755163397335, 'max_depth': 3}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:08,023] Trial 14 finished with value: 0.04422085083959877 and parameters: {'n_estimators': 126, 'learning_rate': 0.49550483874584256, 'max_depth': 20}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:12,727] Trial 15 finished with value: 0.02896874679942917 and parameters: {'n_estimators': 76, 'learning_rate': 0.3318361923333976, 'max_depth': 11}. Best is trial 1 with value: 0.028355409745206624.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:14,347] Trial 16 finished with value: 0.025724527955906053 and parameters: {'n_estimators': 36, 'learning_rate': 0.32258297187571644, 'max_depth': 8}. Best is trial 16 with value: 0.025724527955906053.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:15,309] Trial 17 finished with value: 0.029722993833308536 and parameters: {'n_estimators': 34, 'learning_rate': 0.2164724586927731, 'max_depth': 5}. Best is trial 16 with value: 0.025724527955906053.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:16,868] Trial 18 finished with value: 0.02599421528475156 and parameters: {'n_estimators': 32, 'learning_rate': 0.1337641423482899, 'max_depth': 8}. Best is trial 16 with value: 0.025724527955906053.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:20,327] Trial 19 finished with value: 0.04361864212404591 and parameters: {'n_estimators': 33, 'learning_rate': 0.137970254607148, 'max_depth': 22}. Best is trial 16 with value: 0.025724527955906053.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:23,052] Trial 20 finished with value: 0.03878167170817853 and parameters: {'n_estimators': 29, 'learning_rate': 0.15322295831622665, 'max_depth': 15}. Best is trial 16 with value: 0.025724527955906053.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:25,357] Trial 21 finished with value: 0.025109289501115465 and parameters: {'n_estimators': 52, 'learning_rate': 0.26404557223111974, 'max_depth': 8}. Best is trial 21 with value: 0.025109289501115465.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:28,972] Trial 22 finished with value: 0.025566978856499493 and parameters: {'n_estimators': 72, 'learning_rate': 0.27016418409053033, 'max_depth': 9}. Best is trial 21 with value: 0.025109289501115465.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:34,126] Trial 23 finished with value: 0.03430115669820102 and parameters: {'n_estimators': 68, 'learning_rate': 0.2598945589023574, 'max_depth': 13}. Best is trial 21 with value: 0.025109289501115465.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:36,735] Trial 24 finished with value: 0.027245380885758074 and parameters: {'n_estimators': 46, 'learning_rate': 0.3049047445103504, 'max_depth': 10}. Best is trial 21 with value: 0.025109289501115465.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:37,806] Trial 25 finished with value: 0.03694213800536486 and parameters: {'n_estimators': 94, 'learning_rate': 0.35498447992581, 'max_depth': 2}. Best is trial 21 with value: 0.025109289501115465.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:40,819] Trial 26 finished with value: 0.024885178494794685 and parameters: {'n_estimators': 110, 'learning_rate': 0.2419657432633852, 'max_depth': 5}. Best is trial 26 with value: 0.024885178494794685.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:43,930] Trial 27 finished with value: 0.026226418684645404 and parameters: {'n_estimators': 114, 'learning_rate': 0.26467972376239235, 'max_depth': 5}. Best is trial 26 with value: 0.024885178494794685.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:49,982] Trial 28 finished with value: 0.0428366791175706 and parameters: {'n_estimators': 133, 'learning_rate': 0.23094464689443248, 'max_depth': 18}. Best is trial 26 with value: 0.024885178494794685.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:52,883] Trial 29 finished with value: 0.024680155988751576 and parameters: {'n_estimators': 106, 'learning_rate': 0.1687678371789284, 'max_depth': 5}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:53:56,907] Trial 30 finished with value: 0.025400489158765034 and parameters: {'n_estimators': 146, 'learning_rate': 0.10266149316050607, 'max_depth': 5}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:01,068] Trial 31 finished with value: 0.025588340842100977 and parameters: {'n_estimators': 151, 'learning_rate': 0.10316856768060048, 'max_depth': 5}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:04,575] Trial 32 finished with value: 0.02479598290272468 and parameters: {'n_estimators': 128, 'learning_rate': 0.1734756217007129, 'max_depth': 5}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:05,933] Trial 33 finished with value: 0.04028670267018026 and parameters: {'n_estimators': 120, 'learning_rate': 0.17979117228241417, 'max_depth': 2}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:11,588] Trial 34 finished with value: 0.04373091276475682 and parameters: {'n_estimators': 104, 'learning_rate': 0.2415187612389929, 'max_depth': 32}. Best is trial 29 with value: 0.024680155988751576.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:14,905] Trial 35 finished with value: 0.02365351245106336 and parameters: {'n_estimators': 101, 'learning_rate': 0.16245950860986488, 'max_depth': 6}. Best is trial 35 with value: 0.02365351245106336.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:18,351] Trial 36 finished with value: 0.023584638907102117 and parameters: {'n_estimators': 105, 'learning_rate': 0.16069318847273256, 'max_depth': 6}. Best is trial 36 with value: 0.023584638907102117.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:25,533] Trial 37 finished with value: 0.030229723472785314 and parameters: {'n_estimators': 97, 'learning_rate': 0.094295303357433, 'max_depth': 12}. Best is trial 36 with value: 0.023584638907102117.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:28,827] Trial 38 finished with value: 0.02324837259367487 and parameters: {'n_estimators': 84, 'learning_rate': 0.17251713060020465, 'max_depth': 7}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:32,217] Trial 39 finished with value: 0.024234503430721064 and parameters: {'n_estimators': 83, 'learning_rate': 0.07697484352571086, 'max_depth': 7}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:35,767] Trial 40 finished with value: 0.02860859011134633 and parameters: {'n_estimators': 82, 'learning_rate': 0.04379175685441361, 'max_depth': 7}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:38,648] Trial 41 finished with value: 0.024204819043190245 and parameters: {'n_estimators': 86, 'learning_rate': 0.1275565850915906, 'max_depth': 6}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:42,097] Trial 42 finished with value: 0.02386516953932387 and parameters: {'n_estimators': 86, 'learning_rate': 0.08164239898962522, 'max_depth': 7}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:43,610] Trial 43 finished with value: 0.037644960886538376 and parameters: {'n_estimators': 90, 'learning_rate': 0.11961509961223654, 'max_depth': 3}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:49,781] Trial 44 finished with value: 0.025697547905195392 and parameters: {'n_estimators': 102, 'learning_rate': 0.06631517979398678, 'max_depth': 10}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:55,599] Trial 45 finished with value: 0.05846105682669008 and parameters: {'n_estimators': 62, 'learning_rate': 0.01162197250848307, 'max_depth': 15}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:54:58,650] Trial 46 finished with value: 0.02329082703938587 and parameters: {'n_estimators': 78, 'learning_rate': 0.2072723727990237, 'max_depth': 7}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:55:03,921] Trial 47 finished with value: 0.030078339534063046 and parameters: {'n_estimators': 76, 'learning_rate': 0.2069527064407023, 'max_depth': 12}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:55:05,878] Trial 48 finished with value: 0.033865921922897245 and parameters: {'n_estimators': 117, 'learning_rate': 0.16480282366902063, 'max_depth': 3}. Best is trial 38 with value: 0.02324837259367487.\n",
      "/home/matan/miniconda3/envs/neural_ivd/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "[I 2024-05-13 13:55:09,885] Trial 49 finished with value: 0.028865582077378098 and parameters: {'n_estimators': 67, 'learning_rate': 0.041218990499094554, 'max_depth': 9}. Best is trial 38 with value: 0.02324837259367487.\n",
      "[I 2024-05-13 13:55:09,885] A new study created in memory with name: no-name-24236965-73fb-461a-9c89-5480e093d254\n",
      "[I 2024-05-13 13:55:10,117] Trial 0 finished with value: 0.027890399206092695 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.4094645410606186}. Best is trial 0 with value: 0.027890399206092695.\n",
      "[I 2024-05-13 13:55:11,014] Trial 1 finished with value: 0.028978437858423602 and parameters: {'n_estimators': 146, 'max_depth': 22, 'learning_rate': 0.2542729926707702}. Best is trial 0 with value: 0.027890399206092695.\n",
      "[I 2024-05-13 13:55:11,040] Trial 2 finished with value: 0.028504347752462172 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.1575969437614903}. Best is trial 0 with value: 0.027890399206092695.\n",
      "[I 2024-05-13 13:55:11,535] Trial 3 finished with value: 0.02829640136328003 and parameters: {'n_estimators': 86, 'max_depth': 13, 'learning_rate': 0.2909044021779585}. Best is trial 0 with value: 0.027890399206092695.\n",
      "[I 2024-05-13 13:55:11,713] Trial 4 finished with value: 0.023790771247778304 and parameters: {'n_estimators': 91, 'max_depth': 9, 'learning_rate': 0.20831140188794472}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:12,550] Trial 5 finished with value: 0.03017240865155621 and parameters: {'n_estimators': 21, 'max_depth': 19, 'learning_rate': 0.19133801967135836}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:12,596] Trial 6 finished with value: 0.024812236151331775 and parameters: {'n_estimators': 78, 'max_depth': 6, 'learning_rate': 0.10579701338790061}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:15,226] Trial 7 finished with value: 0.03885549374974329 and parameters: {'n_estimators': 83, 'max_depth': 21, 'learning_rate': 0.020616561741872225}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:15,253] Trial 8 finished with value: 0.026279822191387334 and parameters: {'n_estimators': 92, 'max_depth': 4, 'learning_rate': 0.41045179871936993}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:16,033] Trial 9 finished with value: 0.030519842480433153 and parameters: {'n_estimators': 27, 'max_depth': 32, 'learning_rate': 0.2957349626009125}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:16,625] Trial 10 finished with value: 0.03219951105989565 and parameters: {'n_estimators': 130, 'max_depth': 27, 'learning_rate': 0.48927172639945005}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:16,942] Trial 11 finished with value: 0.02580783770520984 and parameters: {'n_estimators': 59, 'max_depth': 10, 'learning_rate': 0.07387792696195897}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:16,972] Trial 12 finished with value: 0.03621102481441111 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.11197813988282718}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:17,503] Trial 13 finished with value: 0.027904090897079473 and parameters: {'n_estimators': 57, 'max_depth': 12, 'learning_rate': 0.20296074721934873}. Best is trial 4 with value: 0.023790771247778304.\n",
      "[I 2024-05-13 13:55:17,735] Trial 14 finished with value: 0.02290286474808811 and parameters: {'n_estimators': 189, 'max_depth': 8, 'learning_rate': 0.09776401923831893}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:23,133] Trial 15 finished with value: 0.030933742555284027 and parameters: {'n_estimators': 197, 'max_depth': 15, 'learning_rate': 0.015445310445593774}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:23,346] Trial 16 finished with value: 0.024144043539442137 and parameters: {'n_estimators': 155, 'max_depth': 9, 'learning_rate': 0.24347692907366356}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:24,662] Trial 17 finished with value: 0.028706723612734457 and parameters: {'n_estimators': 198, 'max_depth': 17, 'learning_rate': 0.15391231637751}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:24,768] Trial 18 finished with value: 0.02423168765051019 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.32875520824143284}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:26,963] Trial 19 finished with value: 0.0279288332781288 and parameters: {'n_estimators': 170, 'max_depth': 14, 'learning_rate': 0.06724689707965882}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:26,988] Trial 20 finished with value: 0.040428403801665305 and parameters: {'n_estimators': 105, 'max_depth': 2, 'learning_rate': 0.20563609958134693}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:27,197] Trial 21 finished with value: 0.024431451642445867 and parameters: {'n_estimators': 158, 'max_depth': 9, 'learning_rate': 0.24726761405979156}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:27,387] Trial 22 finished with value: 0.025977415973017746 and parameters: {'n_estimators': 184, 'max_depth': 8, 'learning_rate': 0.3627745003636871}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:28,033] Trial 23 finished with value: 0.02731228752642196 and parameters: {'n_estimators': 139, 'max_depth': 12, 'learning_rate': 0.16812388373345555}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:28,960] Trial 24 finished with value: 0.028611244309840442 and parameters: {'n_estimators': 153, 'max_depth': 16, 'learning_rate': 0.22112511705669646}. Best is trial 14 with value: 0.02290286474808811.\n",
      "[I 2024-05-13 13:55:29,105] Trial 25 finished with value: 0.02282597201425729 and parameters: {'n_estimators': 176, 'max_depth': 7, 'learning_rate': 0.12445740120682797}. Best is trial 25 with value: 0.02282597201425729.\n",
      "[I 2024-05-13 13:55:29,205] Trial 26 finished with value: 0.02219718548298423 and parameters: {'n_estimators': 179, 'max_depth': 6, 'learning_rate': 0.11678452806022886}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:29,275] Trial 27 finished with value: 0.024776401273770725 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.09754696189353128}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:29,306] Trial 28 finished with value: 0.04920698149427513 and parameters: {'n_estimators': 168, 'max_depth': 2, 'learning_rate': 0.0497505835345177}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:29,927] Trial 29 finished with value: 0.025741500421934675 and parameters: {'n_estimators': 186, 'max_depth': 11, 'learning_rate': 0.12992616696880036}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:30,071] Trial 30 finished with value: 0.022283881909034964 and parameters: {'n_estimators': 169, 'max_depth': 7, 'learning_rate': 0.132116599577966}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:30,212] Trial 31 finished with value: 0.02265396775587288 and parameters: {'n_estimators': 169, 'max_depth': 7, 'learning_rate': 0.13652701302322742}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:30,308] Trial 32 finished with value: 0.02226684687412078 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.134989241302635}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:30,358] Trial 33 finished with value: 0.02596359105241077 and parameters: {'n_estimators': 167, 'max_depth': 4, 'learning_rate': 0.15409565236014705}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:30,415] Trial 34 finished with value: 0.024024038387727115 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.17794951031088577}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:31,667] Trial 35 finished with value: 0.025328337698682615 and parameters: {'n_estimators': 160, 'max_depth': 11, 'learning_rate': 0.050307970532656426}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:31,745] Trial 36 finished with value: 0.022474672922904792 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.15097481228797438}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:31,790] Trial 37 finished with value: 0.03070325303410136 and parameters: {'n_estimators': 146, 'max_depth': 4, 'learning_rate': 0.08525445920913212}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:32,696] Trial 38 finished with value: 0.02799437487978899 and parameters: {'n_estimators': 132, 'max_depth': 13, 'learning_rate': 0.1450256682678184}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:33,532] Trial 39 finished with value: 0.029883243967297198 and parameters: {'n_estimators': 121, 'max_depth': 24, 'learning_rate': 0.2851443680958977}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:33,617] Trial 40 finished with value: 0.022703609576918367 and parameters: {'n_estimators': 151, 'max_depth': 6, 'learning_rate': 0.18095850164686325}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:33,754] Trial 41 finished with value: 0.02225262813269376 and parameters: {'n_estimators': 165, 'max_depth': 7, 'learning_rate': 0.13011537041462667}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:33,855] Trial 42 finished with value: 0.025494784428682662 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.045809383652641436}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:34,344] Trial 43 finished with value: 0.024224214090467495 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.1158831944065296}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:34,378] Trial 44 finished with value: 0.03152622668741901 and parameters: {'n_estimators': 138, 'max_depth': 3, 'learning_rate': 0.22277284828525615}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:36,775] Trial 45 finished with value: 0.028929733341468044 and parameters: {'n_estimators': 188, 'max_depth': 20, 'learning_rate': 0.08376426471136167}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:37,008] Trial 46 finished with value: 0.023234972067904144 and parameters: {'n_estimators': 193, 'max_depth': 8, 'learning_rate': 0.1721937571774921}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:37,077] Trial 47 finished with value: 0.023960522981673865 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.1343749413732343}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:37,528] Trial 48 finished with value: 0.02423115906409897 and parameters: {'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.1069228764526011}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:38,666] Trial 49 finished with value: 0.029010507578626867 and parameters: {'n_estimators': 146, 'max_depth': 29, 'learning_rate': 0.19124527737367059}. Best is trial 26 with value: 0.02219718548298423.\n",
      "[I 2024-05-13 13:55:38,667] A new study created in memory with name: no-name-c10d9eb8-0e9d-4c27-9a62-15d4a826c460\n",
      "[I 2024-05-13 13:55:38,719] Trial 0 finished with value: 0.024158308925429806 and parameters: {'num_leaves': 78, 'max_depth': 19, 'learning_rate': 0.3607827940113735, 'n_estimators': 65}. Best is trial 0 with value: 0.024158308925429806.\n",
      "[I 2024-05-13 13:55:38,806] Trial 1 finished with value: 0.021455000339712205 and parameters: {'num_leaves': 111, 'max_depth': 28, 'learning_rate': 0.15931094165919749, 'n_estimators': 76}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:38,952] Trial 2 finished with value: 0.02332230115581199 and parameters: {'num_leaves': 220, 'max_depth': 10, 'learning_rate': 0.32103679067213536, 'n_estimators': 146}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:38,981] Trial 3 finished with value: 0.024499387665049582 and parameters: {'num_leaves': 27, 'max_depth': 20, 'learning_rate': 0.37233066788138336, 'n_estimators': 60}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,102] Trial 4 finished with value: 0.021784779680888572 and parameters: {'num_leaves': 130, 'max_depth': 27, 'learning_rate': 0.13158937614912547, 'n_estimators': 100}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,322] Trial 5 finished with value: 0.02195201497192633 and parameters: {'num_leaves': 105, 'max_depth': 17, 'learning_rate': 0.03517858293357548, 'n_estimators': 196}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,354] Trial 6 finished with value: 0.029498115646371753 and parameters: {'num_leaves': 58, 'max_depth': 4, 'learning_rate': 0.13352134786132774, 'n_estimators': 123}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,482] Trial 7 finished with value: 0.02351208431310825 and parameters: {'num_leaves': 102, 'max_depth': 24, 'learning_rate': 0.2913781926827641, 'n_estimators': 156}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,514] Trial 8 finished with value: 0.025146165417882897 and parameters: {'num_leaves': 98, 'max_depth': 9, 'learning_rate': 0.31928662496498494, 'n_estimators': 29}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,523] Trial 9 finished with value: 0.058236652924651904 and parameters: {'num_leaves': 221, 'max_depth': 2, 'learning_rate': 0.3234225456920473, 'n_estimators': 12}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,625] Trial 10 finished with value: 0.02739856653606359 and parameters: {'num_leaves': 154, 'max_depth': 32, 'learning_rate': 0.48268986492436516, 'n_estimators': 81}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,757] Trial 11 finished with value: 0.021908204230088293 and parameters: {'num_leaves': 160, 'max_depth': 32, 'learning_rate': 0.16629148824232676, 'n_estimators': 92}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:39,909] Trial 12 finished with value: 0.021792350900215095 and parameters: {'num_leaves': 157, 'max_depth': 26, 'learning_rate': 0.1726677280604673, 'n_estimators': 113}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:40,009] Trial 13 finished with value: 0.030250536010204672 and parameters: {'num_leaves': 188, 'max_depth': 27, 'learning_rate': 0.04633441841767612, 'n_estimators': 51}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:40,049] Trial 14 finished with value: 0.024847028713945986 and parameters: {'num_leaves': 11, 'max_depth': 28, 'learning_rate': 0.21429014681836753, 'n_estimators': 135}. Best is trial 1 with value: 0.021455000339712205.\n",
      "[I 2024-05-13 13:55:40,181] Trial 15 finished with value: 0.02142868221892027 and parameters: {'num_leaves': 137, 'max_depth': 22, 'learning_rate': 0.0986438006578224, 'n_estimators': 95}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,293] Trial 16 finished with value: 0.021573815206609157 and parameters: {'num_leaves': 50, 'max_depth': 22, 'learning_rate': 0.08442327713667908, 'n_estimators': 168}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,391] Trial 17 finished with value: 0.02264905305796684 and parameters: {'num_leaves': 183, 'max_depth': 13, 'learning_rate': 0.23379910108528526, 'n_estimators': 82}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,460] Trial 18 finished with value: 0.07166622005707081 and parameters: {'num_leaves': 126, 'max_depth': 16, 'learning_rate': 0.011129136409442908, 'n_estimators': 42}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,559] Trial 19 finished with value: 0.02249994743370958 and parameters: {'num_leaves': 129, 'max_depth': 22, 'learning_rate': 0.0912351540633024, 'n_estimators': 68}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,777] Trial 20 finished with value: 0.022620328151124056 and parameters: {'num_leaves': 255, 'max_depth': 30, 'learning_rate': 0.19640541906792103, 'n_estimators': 115}. Best is trial 15 with value: 0.02142868221892027.\n",
      "[I 2024-05-13 13:55:40,902] Trial 21 finished with value: 0.02136574963943984 and parameters: {'num_leaves': 55, 'max_depth': 23, 'learning_rate': 0.09272959026724237, 'n_estimators': 184}. Best is trial 21 with value: 0.02136574963943984.\n",
      "[I 2024-05-13 13:55:41,047] Trial 22 finished with value: 0.020663401293575825 and parameters: {'num_leaves': 71, 'max_depth': 24, 'learning_rate': 0.0959080973897064, 'n_estimators': 183}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,189] Trial 23 finished with value: 0.020845389690308296 and parameters: {'num_leaves': 62, 'max_depth': 24, 'learning_rate': 0.09495976081007697, 'n_estimators': 197}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,329] Trial 24 finished with value: 0.021046118423892753 and parameters: {'num_leaves': 53, 'max_depth': 24, 'learning_rate': 0.058384767421120976, 'n_estimators': 199}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,508] Trial 25 finished with value: 0.0208621641620147 and parameters: {'num_leaves': 77, 'max_depth': 25, 'learning_rate': 0.05714441615883171, 'n_estimators': 196}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,691] Trial 26 finished with value: 0.02773122496176608 and parameters: {'num_leaves': 81, 'max_depth': 20, 'learning_rate': 0.01871455616347839, 'n_estimators': 176}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,757] Trial 27 finished with value: 0.022022723057362806 and parameters: {'num_leaves': 24, 'max_depth': 15, 'learning_rate': 0.12995303270216865, 'n_estimators': 157}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,890] Trial 28 finished with value: 0.022294986443127468 and parameters: {'num_leaves': 79, 'max_depth': 25, 'learning_rate': 0.25408366757003426, 'n_estimators': 186}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:41,968] Trial 29 finished with value: 0.02171765002611769 and parameters: {'num_leaves': 33, 'max_depth': 30, 'learning_rate': 0.06595515056719939, 'n_estimators': 171}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,105] Trial 30 finished with value: 0.02098693599942749 and parameters: {'num_leaves': 69, 'max_depth': 19, 'learning_rate': 0.12437645319280671, 'n_estimators': 189}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,248] Trial 31 finished with value: 0.021308832094110188 and parameters: {'num_leaves': 70, 'max_depth': 19, 'learning_rate': 0.10608154144582597, 'n_estimators': 187}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,405] Trial 32 finished with value: 0.021279217638942766 and parameters: {'num_leaves': 82, 'max_depth': 20, 'learning_rate': 0.06281329823437165, 'n_estimators': 161}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,440] Trial 33 finished with value: 0.033077914768467186 and parameters: {'num_leaves': 4, 'max_depth': 25, 'learning_rate': 0.1393207093148368, 'n_estimators': 200}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,508] Trial 34 finished with value: 0.022075316402484817 and parameters: {'num_leaves': 33, 'max_depth': 21, 'learning_rate': 0.18206536907067397, 'n_estimators': 141}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,622] Trial 35 finished with value: 0.02486763657165719 and parameters: {'num_leaves': 70, 'max_depth': 13, 'learning_rate': 0.40706488238862826, 'n_estimators': 180}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,789] Trial 36 finished with value: 0.021337074043904735 and parameters: {'num_leaves': 91, 'max_depth': 18, 'learning_rate': 0.1199083578994351, 'n_estimators': 189}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:42,957] Trial 37 finished with value: 0.02129908798927872 and parameters: {'num_leaves': 112, 'max_depth': 30, 'learning_rate': 0.14597499085906873, 'n_estimators': 167}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,053] Trial 38 finished with value: 0.022060193504585587 and parameters: {'num_leaves': 40, 'max_depth': 18, 'learning_rate': 0.06640003309701378, 'n_estimators': 151}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,225] Trial 39 finished with value: 0.021803381093479814 and parameters: {'num_leaves': 69, 'max_depth': 26, 'learning_rate': 0.038812463148406036, 'n_estimators': 192}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,395] Trial 40 finished with value: 0.022132242335896824 and parameters: {'num_leaves': 114, 'max_depth': 24, 'learning_rate': 0.20140179406839992, 'n_estimators': 175}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,502] Trial 41 finished with value: 0.02119043432642416 and parameters: {'num_leaves': 48, 'max_depth': 23, 'learning_rate': 0.05885795495344388, 'n_estimators': 200}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,670] Trial 42 finished with value: 0.022785594160439043 and parameters: {'num_leaves': 62, 'max_depth': 28, 'learning_rate': 0.03305708919934651, 'n_estimators': 200}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,828] Trial 43 finished with value: 0.021138441326672593 and parameters: {'num_leaves': 89, 'max_depth': 24, 'learning_rate': 0.12248524801532315, 'n_estimators': 179}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,900] Trial 44 finished with value: 0.023194026191184002 and parameters: {'num_leaves': 19, 'max_depth': 8, 'learning_rate': 0.07941753454743518, 'n_estimators': 190}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:43,976] Trial 45 finished with value: 0.022541358017513672 and parameters: {'num_leaves': 40, 'max_depth': 28, 'learning_rate': 0.15851579608892946, 'n_estimators': 134}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:44,093] Trial 46 finished with value: 0.021003218852917532 and parameters: {'num_leaves': 61, 'max_depth': 26, 'learning_rate': 0.11097387709368771, 'n_estimators': 161}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:44,248] Trial 47 finished with value: 0.02139787530665934 and parameters: {'num_leaves': 96, 'max_depth': 21, 'learning_rate': 0.11324852099350174, 'n_estimators': 162}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:44,353] Trial 48 finished with value: 0.020884652462209535 and parameters: {'num_leaves': 63, 'max_depth': 26, 'learning_rate': 0.15525868923008415, 'n_estimators': 148}. Best is trial 22 with value: 0.020663401293575825.\n",
      "[I 2024-05-13 13:55:44,438] Trial 49 finished with value: 0.02200873635389857 and parameters: {'num_leaves': 69, 'max_depth': 29, 'learning_rate': 0.28748122838909573, 'n_estimators': 146}. Best is trial 22 with value: 0.020663401293575825.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 31, 'n_estimators': 51}\n",
      "Best parameters for SVR: {'C': 2.479459357922161, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best parameters for Gradient Boosting: {'n_estimators': 84, 'learning_rate': 0.17251713060020465, 'max_depth': 7}\n",
      "Best parameters for XGBoost: {'n_estimators': 179, 'max_depth': 6, 'learning_rate': 0.11678452806022886}\n",
      "Best parameters for LightGBM: {'num_leaves': 71, 'max_depth': 24, 'learning_rate': 0.0959080973897064, 'n_estimators': 183}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "target_columns = ['y_ROM']\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "for train_index, test_index in kf.split(df['config_id'].unique()):\n",
    "    df_train = df[df['config_id'].isin(train_index)]\n",
    "    df_test = df[df['config_id'].isin(test_index)]\n",
    "    X_train, X_test = df_train.drop(['config_id'] + target_columns, axis=1), df_test.drop(['config_id'] + target_columns, axis=1)\n",
    "    y_train, y_test = df_train[target_columns], df_test[target_columns]\n",
    "    break\n",
    "\n",
    "# Define the objective function for each model\n",
    "def objective(trial, model_name):\n",
    "    if model_name == \"Random Forest\":\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "        model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "    elif model_name == \"SVR\":\n",
    "        C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
    "        gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "        kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"linear\", \"poly\"])\n",
    "        model = SVR(C=C, gamma=gamma, kernel=kernel)\n",
    "\n",
    "    elif model_name == \"Gradient Boosting\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "\n",
    "    elif model_name == \"XGBoost\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n",
    "        model = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, random_state=42)\n",
    "\n",
    "    elif model_name == \"LightGBM\":\n",
    "        num_leaves = trial.suggest_int(\"num_leaves\", 2, 256)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "        model = lgb.LGBMRegressor(num_leaves=num_leaves, max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, verbose=-1, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.values, preds.ravel()))\n",
    "    return rmse\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=random_state),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=random_state),\n",
    "    \"XGBoost\": xgb.XGBRegressor(random_state=random_state),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=random_state),\n",
    "}\n",
    "\n",
    "# Run optimization\n",
    "res = dict()\n",
    "for model_name in models.keys():\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, model_name), n_trials=50)\n",
    "    res[model_name] = study.best_params\n",
    "\n",
    "for model_name, best_params in res.items():\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a model and dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to save along with the model\n",
    "model_params = {\n",
    "    'hparams': hparams,\n",
    "    'state_dict': trained_models[0].state_dict(),\n",
    "    'feature_names': df.columns,\n",
    "    'feature_bounds': train_column_bounds\n",
    "}\n",
    "\n",
    "# Save the model and parameters to a file\n",
    "torch.save(model_params, 'model_large_mse.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "\n",
    "for train_index, val_index in kf.split(df['config_id'].unique()):\n",
    "    df_train = df[df['config_id'].isin(train_index)]\n",
    "    df_val = df[df['config_id'].isin(val_index)]\n",
    "\n",
    "    df_train.to_csv('datasets/Large/train_df_large_rom_norm.csv', index=False)\n",
    "    df_val.to_csv('datasets/Large/val_df_large_rom_norm.csv', index=False)\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
